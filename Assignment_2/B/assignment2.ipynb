{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Intelligence - Group 53 - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ufc_data():\n",
    "    \n",
    "    path = Path(\"../data/data.csv\")\n",
    "    ufc_data = pd.read_csv(path, header=0, delimiter=\",\")\n",
    "    \n",
    "    return ufc_data\n",
    "\n",
    "data_ufc = load_ufc_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the data one should first of all understand the business. Below one can find a glossary of terms used in MMA (UFC) and their explanations.\n",
    "* **Knockdown**:  A fight-ending strike. If a fighter loses consciousness (\"goes limp\") as a result of legal strikes it is declared a KO.\n",
    "* **(Guard) pass**: A guard pass is simply a way for the fighter on top to get past the legs of the fighter on the bottom in order to reach a dominant position on the ground\n",
    "* **Reversal**: Transition from a neutral or inferior position to a dominant position\n",
    "* **Submission**: A submission is a combat sports term for yielding to the opponent, and hence resulting in an immediate defeat. The submission - then also referred to as a \"tap out\" or \"tapping out\" - is often performed by visibly tapping the floor or the opponent with the hand or in some cases with the foot, or by saying the word 'tap' to signal the opponent and/or the referee of the submission\n",
    "* **Takedown**: A takedown is a technique that involves off-balancing an opponent and bringing him or her to the ground with the attacker landing on top.\n",
    "* **Strikes**: There are two different groupings for strikes. \n",
    "  * based on body sections: **HEAD**, **BODY**, **LEG** \n",
    "  * based on positions/ranges\n",
    "    * **Clinche**: A position in which two standing individuals have grabbed ahold of one another. Strikes given and taken in a clinche position.\n",
    "    * **Ground**: Strikes given and taken when the fighters are on the ground\n",
    "    * **Distance**: Distance strikes are all strikes that are not clinche-strikes or ground strikes. This is the most common type of striking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the characteristics of the dataset (size, attribute types and semantics as discussed in class, value ranges, sparsity, min/max values, outliers, missing values, ...), and describe this in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following clustering of attributes is based on logical grouping and not on the attribute type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nominal attributes | Description \n",
    "--- | --- \n",
    "r_fighter | Name of red fighter \n",
    "b_fighter | Name of blue fighter\n",
    "Referee | Name of Referee\n",
    "location | Fight location\n",
    "weight_class | Weight class this the fighters of this bout belong two\n",
    "b/r_Stance | Fighting stance (which foot is placed closer to the opponent. E.g. left in orthodox stance and right in southpaw)\n",
    "Ordinal attributes | Description\n",
    "--- | --- \n",
    "Date | Date of fight\n",
    "\n",
    "Binary attributes | Description\n",
    "--- | ---\n",
    "title_bout | Stating whether the bout was a title bout\n",
    "Winner | Winner of the fight\n",
    "\n",
    "Interval attributes | Description\n",
    "--- | --- \n",
    "no_of_rounds | Number of rounds the bout had.\n",
    "b/r_total_rounds_fought | Number of rounds the fighter fought in total\n",
    "b/r_draw | How many draws did the fighter have\n",
    "b/r_current_loss_streak | How many fights did the fighter lose in a row since last win\n",
    "b/r_current_win_streak | How many fights did the fighter win in a row since the last loss\n",
    "b/r_B_longest_win_streak | How many fights did the fighter lose in a row at his/her longest\n",
    "b/r_losses | Total number of losses for the fighter\n",
    "b/r_total_time_fought(seconds) | Total fighting time in seconds\n",
    "b/r_total_title_bouts | How many title bouts did the fighter have so far\n",
    "b/r_win_by_Decision_Majority | ...\n",
    "b/r_win_by_Decision_Split | ...\n",
    "b/r_win_by_Decision_Unanimous | ...\n",
    "b/r_win_by_KO/TKO | ... \n",
    "b/r_win_by_Submission | ...\n",
    "b/r_win_by_TKO_Doctor_Stoppage | ...\n",
    "b/r_wins | Total number of wins for the fighter\n",
    "b/r_Height_cms | The fighter's height\n",
    "b/r_Reach_cms | The fighter's reach\n",
    "b/r_Weight_lbs | The fighter's weight in lbs\n",
    "b/r_age | Age of fighter\n",
    "\n",
    "Ratio attributes | Description\n",
    "--- | ---\n",
    "b/r_avg_BODY_att | Average body attacks attended (fighter level)\n",
    "b/r_avg_BODY_landed | Average attacks landed (fighter level)\n",
    "b/r_avg_HEAD_att | Average head attacks attended (fighter level)\n",
    "b/r_avg_HEAD_landed | Average head attacks landed (fighter level)\n",
    "b/r_avg_LEG_att |  Average leg attacks attended (fighter level)\n",
    "b/r_avg_LEG_landed |  Average leg attacks landed (fighter level)\n",
    "b/r_avg_CLINCH_att | Average clinches attended (fighter level)\n",
    "b/r_avg_CLINCH_landed | Average clinches landed (fighter level)\n",
    "b/r_avg_DISTANCE_att | ...\n",
    "b/r_avg_DISTANCE_landed | ...\n",
    "b/r_avg_GROUND_att | ...\n",
    "b/r_avg_GROUND_landed | ...\n",
    "b/r_avg_SIG_STR_att | Average significant strikes attended (fighter level)\n",
    "b/r_avg_SIG_STR_landed | Average significant strikes landed (fighter level)\n",
    "b/r_avg_SIG_STR_pct | ...\n",
    "b/r_avg_TD_att | Average tackedowns (fighter level)\n",
    "b/r_avg_TD_landed | Average tackedowns landed (fighter level)\n",
    "b/r_avg_TD_pct | ...\n",
    "b/r_avg_TOTAL_STR_att | Average total strikes attended (fighter level)\n",
    "b/r_avg_TOTAL_STR_landed | Average total strikes landed (fighter level)\n",
    "b/r_avg_KD | Average knockdowns (fighter level)\n",
    "b/r_avg_PASS | Average passes (fighter level)\n",
    "b/r_avg_REV | Average reversals (fighter level)\n",
    "b/r_avg_SUB_ATT | Average submissions (fighter level)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assertions passed. Check the assertions to learn more about the semantics of this data set.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average, Min/max values, Variance, standard deviation, mode, skewness, Correlation between attributes\n",
    "# Cross-check semantics and attribute values!\n",
    "# Check data volumes \n",
    "\n",
    "def basic_statistics():\n",
    "    \n",
    "    return None\n",
    "\n",
    "def semantics_check():\n",
    "    # R_avg_TOTAL_STR_att = r_avg_BODY_att + r_avg_HEAD_att + r_avg_LEG_att + r_avg_CLINCH_att + r_avg_DISTANCE_att + r_avg_GROUND_att   \n",
    "    # R_avg_SIG_STR_att =  r_avg_BODY_att + r_avg_HEAD_att + r_avg_LEG_att\n",
    "    # R_avg_BODY_att > r_avg_BODY_landed\n",
    "    # b/r_current_win_streak < b/r_wins\n",
    "    # b/r_current_loss_streak < b/r_losses \n",
    "    # b/r_wins = b/r_win_by_Decision_Majority + b/r_win_by_Decision_Split + b/r_win_by_Decision_Unanimous \n",
    "    # +b/r_win_by_KO/TKO + b/r_win_by_Submission + b/r_win_by_TKO_Doctor_Stoppage\n",
    "    data_ufc_check = data_ufc.copy()\n",
    "    data_ufc_check.dropna(inplace=True)\n",
    "       \n",
    "    assert np.allclose(data_ufc_check.loc[:,'R_avg_SIG_STR_att'],\n",
    "                data_ufc_check.loc[:,['R_avg_CLINCH_att','R_avg_DISTANCE_att',\n",
    "                                      'R_avg_GROUND_att']].sum(axis=1), \n",
    "                rtol=0.00001)\n",
    "    \n",
    "    assert np.allclose(data_ufc_check.loc[:,'R_avg_SIG_STR_att'],\n",
    "                data_ufc_check.loc[:,['R_avg_BODY_att','R_avg_HEAD_att','R_avg_LEG_att']].sum(axis=1), \n",
    "                rtol=0.00001)\n",
    "                         \n",
    "    return \"Assertions passed. Check the assertions to learn more about the semantics of this data set.\"\n",
    "\n",
    "semantics_check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual exploration\n",
    "# Plot basic statistics\n",
    "# Identify interesting subpopulations\n",
    "## E.g. only male fighters and only 4-5 most popular weight classes\n",
    "# Form hypotheses and identify actions\n",
    "## E.g. which attributes do contribute significantly to the weight class\n",
    "# Transform the hypothesis into a data mining goal, if possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify special values and catalog their meaning\n",
    "# Find missing values and outliers.\n",
    "# Check for deviations, decide whether it is “noise” or may indicate an interesting phenomenon.\n",
    "# Check for plausability of values\n",
    "# Verify that the meanings of attributes and contained values fit\n",
    "# Establish the meaning of missing data ! Why is it missing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling: If the entire dataset is too large to be processed in its entirety, choose a subsampling strategy to get the dataset to a manageable size. Describe in your report why and how you did it. Make sure your experiment is repeatable. (No manual selection of instances, everything must be in code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and outliers\n",
    "# eg. by deletion or imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Get the data into the form needed for training your two algorithms. Describe your preprocessing steps (e.g. transcoding, scaling), why you did it and how you did it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to different attribute types (Binning, 1-to-n coding, …)\n",
    "# Add new attributes to the accessed data\n",
    "# Decide if any attribute should be normalized\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick two significantly different classification algorithms, i.e. NO two variations of the same algorithm.\n",
    "* SVM and Random Forest\n",
    "* Class attribute: weight_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe why you chose the respective algorithms and briefly summarize their characteristics and the semantics underlying its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test desgin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be tested using an incrementally varying train/test split approach. We will start with a split of 5%/95% (train/test) and increment the split ratio by 10% until 95%/5% is reached.\n",
    "For each training set size we will perform multiple runs to observe the sensitivity to the actual subset used for training a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "# Paramters\n",
    "## Explore paramters with Grid Search and cross validation\n",
    "# Training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your two algorithms in 3 separate experiment tracks as detailed below and evaluate your results with a reasonable quality measure for your algorithms (e.g.: (micro/macro) Precision/Recall, Mean Absolute Error,…). Interpret your results using both graphs and summaries (e.g. confusion matrices). For each of the 3 experiment tracks you should separately vary and document:\n",
    "* Parameters: If the classifier has specific parameters, explore their effect with different settings using 10-fold cross-validation and document the parameters and the results and analyze the sensitivity of classification outcomes against these parameters. Specifically, test extreme/obviously wrong settings and analyze the results\n",
    "* Scaling: where possible, try different scaling approaches (min/max, zero mean/unit variance, length) using the best parameters identified above and observe the difference in classification performance using 10-fold cross-validation. Analyze the reasons for the effects observed, test useful and also non-useful (!) scalings and summarize your findings as well as analyze reasons why specific scalings make sense in a given setting.\n",
    "* Training / test set splits: Use the best parameter setting and scaling identified above and evaluate the effect of different training and test set splits. Start with a small training set and increase it in small increments (e.g. 10 sets from 5% / 95% (train/test) in 10%-increments to 95%/5% (train/test)) and observe performance changes. Perform multiple runs with each training set size to observe the sensitivity to the actual subset used for training a specific run. Analyze the variance in performance obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asses Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What trends do you observe in each set of experiments?\n",
    "* How easy was it to interpret the algorithm and its performance?\n",
    "* Which classes are most frequently mixed-up? (and why?)\n",
    "* What parameter settings cause performance changes?\n",
    "* Do both algorithms show the same behavior in performance, performance degradation / robustness against\n",
    "  * smaller and larger training set sizes?\n",
    "  * variations in parameter settings?\n",
    "* Did you observe or can you force and document characteristics such as over-learning?\n",
    "* How does the performance change with different amounts of training data being available? What are the best scalings (per attribute / per vector) and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
