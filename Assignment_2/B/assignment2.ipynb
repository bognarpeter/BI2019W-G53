{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Intelligence - Group 53 - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.pylab as plt\n",
    "import scipy.sparse as sparse\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.stats import ks_2samp\n",
    "import seaborn as sns\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the data one should first of all understand the business. Below one can find a glossary of terms used in MMA (UFC) and their explanations.\n",
    "* **Knockdown**:  A fight-ending strike. If a fighter loses consciousness (\"goes limp\") as a result of legal strikes it is declared a KO.\n",
    "* **(Guard) pass**: A guard pass is simply a way for the fighter on top to get past the legs of the fighter on the bottom in order to reach a dominant position on the ground\n",
    "* **Reversal**: Transition from a neutral or inferior position to a dominant position\n",
    "* **Submission**: A submission is a combat sports term for yielding to the opponent, and hence resulting in an immediate defeat. The submission - then also referred to as a \"tap out\" or \"tapping out\" - is often performed by visibly tapping the floor or the opponent with the hand or in some cases with the foot, or by saying the word 'tap' to signal the opponent and/or the referee of the submission\n",
    "* **Takedown**: A takedown is a technique that involves off-balancing an opponent and bringing him or her to the ground with the attacker landing on top.\n",
    "* **Strikes**: There are two different groupings for strikes. \n",
    "  * based on body sections: **HEAD**, **BODY**, **LEG** \n",
    "  * based on positions/ranges\n",
    "    * **Clinch**: A position in which two standing individuals have grabbed ahold of one another. Strikes given and taken in a clinch position.\n",
    "    * **Ground**: Strikes given and taken when the fighters are on the ground\n",
    "    * **Distance**: Distance strikes are all strikes that are not clinche-strikes or ground strikes. This is the most common type of striking.\n",
    "* **Stance**: Which foot is placed closer to the opponent. E.g. left in orthodox stance and right in southpaw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the characteristics of the dataset (size, attribute types and semantics as discussed in class, value ranges, sparsity, min/max values, outliers, missing values, ...), and describe this in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following clustering of attributes is based on logical grouping and not on the attribute type. Many attributes are prefixed with either 'r' or 'b' which stands for red or blue fighter. To not copy every attribute description for each prefix those attributes in the following tables are prefixed with b/r_.\n",
    "\n",
    "#### Bout stats\n",
    "Attribute | Description | Attribute type \n",
    "--- | --- | ---\n",
    "Referee | Name of Referee | Nominal\n",
    "location | Fight location | Nominal\n",
    "weight_class | Weight class of this bout and fighters | Ordinal\n",
    "Date | Date of fight | Ordinal\n",
    "title_bout | Stating whether the bout was a title bout | Binary\n",
    "Winner | Winner of the fight | Nominal\n",
    "no_of_rounds | Number of rounds the bout had. | Ratio\n",
    "\n",
    "#### Basic fighter stats\n",
    "Attribute | Description | Attribute type \n",
    "--- | --- | ---\n",
    "b/r_fighter | Name of respective fighter | Nominal\n",
    "b/r_Stance | Fighting stance | Nominal\n",
    "b/r_age | Age of fighter | Ratio\n",
    "b/r_Height_cms | The fighter's height | Ratio\n",
    "b/r_Reach_cms | The fighter's reach | Ratio\n",
    "b/r_Weight_lbs | The fighter's weight in lbs | Ratio\n",
    "\n",
    "#### Fighter bout stats\n",
    "Attribute | Description | Attribute type \n",
    "--- | --- | ---\n",
    "b/r_win_by_Decision_Majority | Wins by Decision of the majority | Ratio\n",
    "b/r_win_by_Decision_Split | Wins by Decision Split | Ratio\n",
    "b/r_win_by_Decision_Unanimous | Wins by Decision Unanimous | Ratio\n",
    "b/r_win_by_KO/TKO | Wins by Knockout or technical Knockout | Ratio\n",
    "b/r_win_by_Submission | Wins by submission | Ratio\n",
    "b/r_win_by_TKO_Doctor_Stoppage | Wins due to doctor stopping the fight | Ratio\n",
    "b/r_wins | Total number of wins for the fighter | Ratio\n",
    "b/r_losses | Total number of losses for the fighter | Ratio\n",
    "b/r_draw | How many draws did the fighter have | Ratio\n",
    "b/r_current_lose_streak | How many fights did the fighter lose in a row since last win | Ratio\n",
    "b/r_current_win_streak | How many fights did the fighter win in a row since the last loss | Ratio\n",
    "b/r_longest_win_streak | How many fights did the fighter win in a row at his/her longest | Ratio\n",
    "b/r_total_rounds_fought | Number of rounds the fighter fought in total | Ratio\n",
    "b/r_total_time_fought(seconds) | Total fighting time in seconds | Ratio\n",
    "b/r_total_title_bouts | How many title bouts did the fighter have so far | Ratio\n",
    "\n",
    "#### Fighter infight moves stats \n",
    "Attribute | Description | Attribute type \n",
    "--- | --- | ---\n",
    "b/r_avg_BODY_att | Average body attacks attended (fighter level) | Ratio\n",
    "b/r_avg_BODY_landed | Average attacks landed (fighter level) | Ratio\n",
    "b/r_avg_HEAD_att | Average head attacks attended (fighter level) | Ratio\n",
    "b/r_avg_HEAD_landed | Average head attacks landed (fighter level) | Ratio\n",
    "b/r_avg_LEG_att |  Average leg attacks attended (fighter level) | Ratio\n",
    "b/r_avg_LEG_landed |  Average leg attacks landed (fighter level) | Ratio\n",
    "b/r_avg_CLINCH_att | Average clinches attended (fighter level) | Ratio\n",
    "b/r_avg_CLINCH_landed | Average clinches landed (fighter level) | Ratio\n",
    "b/r_avg_DISTANCE_att | Average distance strikes attended (fighter level) | Ratio\n",
    "b/r_avg_DISTANCE_landed | Average distance strikes landed (fighter level) | Ratio\n",
    "b/r_avg_GROUND_att | Average ground strikes attended (fighter level) | Ratio\n",
    "b/r_avg_GROUND_landed | Average ground strikes landed (fighter level) | Ratio\n",
    "b/r_avg_SIG_STR_att | Average significant strikes attended (fighter level) | Ratio\n",
    "b/r_avg_SIG_STR_landed | Average significant strikes landed (fighter level) | Ratio\n",
    "b/r_avg_SIG_STR_pct | | Ratio\n",
    "b/r_avg_TD_att | Average tackedowns (fighter level) | Ratio\n",
    "b/r_avg_TD_landed | Average tackedowns landed (fighter level) | Ratio\n",
    "b/r_avg_TD_pct | | Ratio\n",
    "b/r_avg_TOTAL_STR_att | Average total strikes attended (fighter level) | Ratio\n",
    "b/r_avg_TOTAL_STR_landed | Average total strikes landed (fighter level) | Ratio\n",
    "b/r_avg_KD | Average knockdowns (fighter level) | Ratio\n",
    "b/r_avg_PASS | Average passes (fighter level) | Ratio\n",
    "b/r_avg_REV | Average reversals (fighter level) | Ratio\n",
    "b/r_avg_SUB_ATT | Average submissions (fighter level) | Ratio\n",
    "\n",
    "#### Unkown attributes\n",
    "Attribute | Description | Attribute type \n",
    "--- | --- | ---\n",
    "b/r_avg_opp_BODY_att | Average body attacks attended (fighter level) | Ratio\n",
    "b/r_avg_opp_BODY_landed | Average attacks landed (fighter level) | Ratio\n",
    "b/r_avg_opp_HEAD_att | Average head attacks attended (fighter level) | Ratio\n",
    "b/r_avg_opp_HEAD_landed | Average head attacks landed (fighter level) | Ratio\n",
    "b/r_avg_opp_LEG_att |  Average leg attacks attended (fighter level) | Ratio\n",
    "b/r_avg_opp_LEG_landed |  Average leg attacks landed (fighter level) | Ratio\n",
    "b/r_avg_opp_CLINCH_att | Average clinches attended (fighter level) | Ratio\n",
    "b/r_avg_opp_CLINCH_landed | Average clinches landed (fighter level) | Ratio\n",
    "b/r_avg_opp_DISTANCE_att | Average distance strikes attended (fighter level) | Ratio\n",
    "b/r_avg_opp_DISTANCE_landed | Average distance strikes landed (fighter level) | Ratio\n",
    "b/r_avg_opp_GROUND_att | Average ground strikes attended (fighter level) | Ratio\n",
    "b/r_avg_opp_GROUND_landed | Average ground strikes landed (fighter level) | Ratio\n",
    "b/r_avg_opp_SIG_STR_att | Average significant strikes attended (fighter level) | Ratio\n",
    "b/r_avg_opp_SIG_STR_landed | Average significant strikes landed (fighter level) | Ratio\n",
    "b/r_avg_opp_SIG_STR_pct | | Ratio\n",
    "b/r_avg_opp_TD_att | Average tackedowns (fighter level) | Ratio\n",
    "b/r_avg_opp_TD_landed | Average tackedowns landed (fighter level) | Ratio\n",
    "b/r_avg_opp_TD_pct | | Ratio\n",
    "b/r_avg_opp_TOTAL_STR_att | Average total strikes attended (fighter level) | Ratio\n",
    "b/r_avg_opp_TOTAL_STR_landed | Average total strikes landed (fighter level) | Ratio\n",
    "b/r_avg_opp_KD | Average knockdowns (fighter level) | Ratio\n",
    "b/r_avg_opp_PASS | Average passes (fighter level) | Ratio\n",
    "b/r_avg_opp_REV | Average reversals (fighter level) | Ratio\n",
    "b/r_avg_opp_SUB_ATT | Average submissions (fighter level) | Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clustered the attributes into five logical clusters. The first one, \"Bout stats\", gives away basic information about the bout itself ( e.g. when it took place, which weight class, who was the referee, ...).  Mostly nominal and ordinal attributes are grouped here. The second cluster is about basic fighter attributes of descriptive nature (height, weight, age, ...). The third cluster captures basic stats about the fighter. As already mentioned there are two fighter attributes for each fighter which differ only in the prefix. (R_ or B_). This cluster has also one aggregated attribute \"R/B_wins\" which should be the sum of six other \"win characteristics\" referring to the way the fighter won (e.g. R_win_by_KO/TKO). It is a first sign of Colinearity between the sub characteristics of win and win itself. The forth cluster contains stats about the different moves and strikes the fighters did in their fights so far. It also contains aggregated attributes such as b/r_avg_opp_SIG_STR_att and b/r_avg_opp_SIG_STR_landed. Later two attributes aggregate \"HEAD, BODY, LEG\" as well as \"DISTANCE, GROUND, CLINCH\" strikes, attended and landed respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-Identify data and method of capture\n",
    "-Perform basic statistical analysis\n",
    "    “For each attribute compute the basic statistics”\n",
    "    - Average\n",
    "    - Min/max values\n",
    "    - Variance, standard deviation, mode, skewness, …\n",
    "    - Histogram: encoding issues (0, 99, -1, 1.1.1900, …)\n",
    "    - Correlation between attributes\n",
    "'''\n",
    "\n",
    "def load_ufc_data():\n",
    "    \n",
    "    path = Path(\"../source_data/data.csv\")\n",
    "    ufc_data = pd.read_csv(path, header=0, delimiter=\",\",encoding ='utf-8')\n",
    "    \n",
    "    return ufc_data\n",
    "\n",
    "data_ufc = load_ufc_data()\n",
    "\n",
    "def semantics_check():\n",
    "    data_ufc_check = data_ufc.copy()\n",
    "    data_ufc_check.dropna(inplace=True)\n",
    "    \n",
    "    # Current win streak must be smaller or equal than wins\n",
    "    assert np.less_equal(data_ufc_check['R_current_win_streak'].values, \n",
    "                               data_ufc_check['R_wins'].values).all()\n",
    "    \n",
    "    # Current lose streak must be smaller or equal than total losses\n",
    "    assert np.less_equal(data_ufc_check['R_current_lose_streak'].values, \n",
    "                               data_ufc_check['R_losses'].values).all()\n",
    "    \n",
    "    # Wins must be the sum of all sub win characteristics\n",
    "    # Is not always the case, that is why the condition is weaker here. Maybe data quality issue\n",
    "    np.less_equal(data_ufc_check.loc[:,'R_wins'],\n",
    "                        data_ufc_check.loc[:,['R_win_by_Decision_Majority',\n",
    "                                              'R_win_by_Decision_Split',\n",
    "                                              'R_win_by_Decision_Unanimous',\n",
    "                                              'R_win_by_KO/TKO',\n",
    "                                              'R_win_by_Submission',\n",
    "                                              'R_win_by_TKO_Doctor_Stoppage']].sum(axis=1)).all()\n",
    "                       \n",
    "    \n",
    "       \n",
    "    # Signficant strikes must equal the sum of each categorized strike group's characteristics  \n",
    "    assert np.allclose(data_ufc_check.loc[:,'R_avg_SIG_STR_att'],\n",
    "                data_ufc_check.loc[:,['R_avg_CLINCH_att','R_avg_DISTANCE_att',\n",
    "                                      'R_avg_GROUND_att']].sum(axis=1), \n",
    "                rtol=0.00001)\n",
    "    assert np.allclose(data_ufc_check.loc[:,'R_avg_SIG_STR_att'],\n",
    "                data_ufc_check.loc[:,['R_avg_BODY_att','R_avg_HEAD_att',\n",
    "                                      'R_avg_LEG_att']].sum(axis=1), \n",
    "                rtol=0.00001)\n",
    "    assert np.allclose(data_ufc_check.loc[:,['R_avg_CLINCH_att','R_avg_DISTANCE_att',\n",
    "                                             'R_avg_GROUND_att']].sum(axis=1),\n",
    "                data_ufc_check.loc[:,['R_avg_BODY_att','R_avg_HEAD_att',\n",
    "                                      'R_avg_LEG_att']].sum(axis=1), \n",
    "                rtol=0.00001)\n",
    "    \n",
    "    # Strikes based on body sections and positions/ranges. \n",
    "    # There must be more or euqal attended strikes than landed\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_HEAD_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_HEAD_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_BODY_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_BODY_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_LEG_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_LEG_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_CLINCH_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_CLINCH_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_DISTANCE_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_DISTANCE_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_GROUND_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_GROUND_landed'].values).all()\n",
    "    \n",
    "    # Takedowns, significant strikes, total strikes\n",
    "    # There must be more or euqal attended strikes/moves than landed\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_SIG_STR_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_SIG_STR_landed'].values).all()  \n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_TD_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_TD_landed'].values).all()\n",
    "    assert np.greater_equal(data_ufc_check.loc[:,'R_avg_TOTAL_STR_att'].values,\n",
    "                   data_ufc_check.loc[:,'R_avg_TOTAL_STR_landed'].values).all()\n",
    "    return \"Assertions passed. Check the assertions to learn more about the semantics of this data set.\"\n",
    "semantics_check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition \"Wins must be the sum of all sub win characteristics\" is not always fullfiled. Only the condition \"sum sub win characteristics <= wins\" is fullfilled. All other semantics are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether R and B are from the same distribution\n",
    "r_attributes = ['R_age','R_Height_cms', 'R_Weight_lbs', 'R_Reach_cms',\n",
    "                'R_avg_SIG_STR_att', 'R_avg_SIG_STR_landed', 'R_avg_TD_att',\n",
    "                'R_avg_TD_landed', 'R_avg_KD', 'R_wins', 'R_losses',\n",
    "                'R_total_time_fought(seconds)']\n",
    "b_attributes = ['B_age', 'B_Height_cms', 'B_Weight_lbs', 'B_Reach_cms',\n",
    "                'B_avg_SIG_STR_att', 'B_avg_SIG_STR_landed', 'B_avg_TD_att',\n",
    "                'B_avg_TD_landed', 'B_avg_KD', 'B_wins', 'B_losses',\n",
    "                'B_total_time_fought(seconds)']\n",
    "for i in range(len(r_attributes)):\n",
    "    print(r_attributes[i])\n",
    "    data = data_ufc.loc[:,[r_attributes[i], b_attributes[i]]].dropna()\n",
    "    x = data[b_attributes[i]].sort_values()\n",
    "    y = data[r_attributes[i]].sort_values()\n",
    "    print(ks_2samp(x,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, a lot of R and B attribute pairs do not come from the same distribution as indicated by small p-values. It seems that there are e.g. totally different distributions in age between the red and the blue fighter. Also the differently distributed wins are somewhat suspicious. This we need to re-check again with a histogram in the data exploration section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_statistics(data):\n",
    "    print(data.describe())\n",
    "    \n",
    "    \n",
    "# Dataframes of clustered attributes in \"Data understanding\"\n",
    "data_ufc_basic_bout_stats = data_ufc.loc[:,['Referee',\n",
    "                                            'location',\n",
    "                                            'weight_class',\n",
    "                                            'date',\n",
    "                                            'title_bout',\n",
    "                                            'Winner', \n",
    "                                            'no_of_rounds']]\n",
    "\n",
    "data_ufc_basic_fighter_stats_R = data_ufc.loc[:,['R_age', 'R_Height_cms', 'R_Weight_lbs', 'R_Reach_cms']]\n",
    "\n",
    "data_ufc_fighter_bout_stats_R = data_ufc.loc[:,['R_win_by_Decision_Majority',\n",
    "                                              'R_win_by_Decision_Split',\n",
    "                                              'R_win_by_Decision_Unanimous',\n",
    "                                              'R_win_by_KO/TKO',\n",
    "                                              'R_win_by_Submission',\n",
    "                                              'R_win_by_TKO_Doctor_Stoppage',\n",
    "                                              'R_wins',\n",
    "                                              'R_losses',\n",
    "                                              'R_draw',\n",
    "                                              'R_current_lose_streak',\n",
    "                                              'R_current_win_streak',\n",
    "                                              'R_longest_win_streak',\n",
    "                                              'R_total_rounds_fought',\n",
    "                                              'R_total_time_fought(seconds)',\n",
    "                                              'R_total_title_bouts']]\n",
    "\n",
    "data_ufc_fighter_infight_moves_stats_R = data_ufc.loc[:, ['R_avg_BODY_att',\n",
    "                                                        'R_avg_BODY_landed',\n",
    "                                                        'R_avg_HEAD_att',\n",
    "                                                        'R_avg_HEAD_landed',\n",
    "                                                        'R_avg_LEG_att',\n",
    "                                                        'R_avg_LEG_landed',\n",
    "                                                        'R_avg_CLINCH_att',\n",
    "                                                        'R_avg_CLINCH_landed',\n",
    "                                                        'R_avg_DISTANCE_att',\n",
    "                                                        'R_avg_DISTANCE_landed',\n",
    "                                                        'R_avg_GROUND_att',\n",
    "                                                        'R_avg_GROUND_landed',\n",
    "                                                        'R_avg_SIG_STR_att',\n",
    "                                                        'R_avg_SIG_STR_landed',\n",
    "                                                        'R_avg_SIG_STR_pct',\n",
    "                                                        'R_avg_TD_att',\n",
    "                                                        'R_avg_TD_landed',\n",
    "                                                        'R_avg_TD_pct',\n",
    "                                                        'R_avg_TOTAL_STR_att',\n",
    "                                                        'R_avg_TOTAL_STR_landed',\n",
    "                                                        'R_avg_KD',\n",
    "                                                        'R_avg_PASS',\n",
    "                                                        'R_avg_REV',\n",
    "                                                        'R_avg_SUB_ATT']]\n",
    "\n",
    "# B fighter stats\n",
    "data_ufc_basic_fighter_stats_B = data_ufc.loc[:,['B_age', 'B_Height_cms', 'B_Weight_lbs', 'B_Reach_cms']]\n",
    "\n",
    "data_ufc_fighter_bout_stats_B = data_ufc.loc[:,['B_win_by_Decision_Majority',\n",
    "                                              'B_win_by_Decision_Split',\n",
    "                                              'B_win_by_Decision_Unanimous',\n",
    "                                              'B_win_by_KO/TKO',\n",
    "                                              'B_win_by_Submission',\n",
    "                                              'B_win_by_TKO_Doctor_Stoppage',\n",
    "                                              'B_wins',\n",
    "                                              'B_losses',\n",
    "                                              'B_draw',\n",
    "                                              'B_current_lose_streak',\n",
    "                                              'B_current_win_streak',\n",
    "                                              'B_longest_win_streak',\n",
    "                                              'B_total_rounds_fought',\n",
    "                                              'B_total_time_fought(seconds)',\n",
    "                                              'B_total_title_bouts']]\n",
    "\n",
    "data_ufc_fighter_infight_moves_stats_B = data_ufc.loc[:, ['B_avg_BODY_att',\n",
    "                                                        'B_avg_BODY_landed',\n",
    "                                                        'B_avg_HEAD_att',\n",
    "                                                        'B_avg_HEAD_landed',\n",
    "                                                        'B_avg_LEG_att',\n",
    "                                                        'B_avg_LEG_landed',\n",
    "                                                        'B_avg_CLINCH_att',\n",
    "                                                        'B_avg_CLINCH_landed',\n",
    "                                                        'B_avg_DISTANCE_att',\n",
    "                                                        'B_avg_DISTANCE_landed',\n",
    "                                                        'B_avg_GROUND_att',\n",
    "                                                        'B_avg_GROUND_landed',\n",
    "                                                        'B_avg_SIG_STR_att',\n",
    "                                                        'B_avg_SIG_STR_landed',\n",
    "                                                        'B_avg_SIG_STR_pct',\n",
    "                                                        'B_avg_TD_att',\n",
    "                                                        'B_avg_TD_landed',\n",
    "                                                        'B_avg_TD_pct',\n",
    "                                                        'B_avg_TOTAL_STR_att',\n",
    "                                                        'B_avg_TOTAL_STR_landed',\n",
    "                                                        'B_avg_KD',\n",
    "                                                        'B_avg_PASS',\n",
    "                                                        'B_avg_REV',\n",
    "                                                        'B_avg_SUB_ATT']]\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Bout stats\")\n",
    "basic_statistics(data_ufc_basic_bout_stats['no_of_rounds'])\n",
    "\n",
    "print(\"Basic fighter stats\")\n",
    "basic_statistics(data_ufc_basic_fighter_stats_R)\n",
    "\n",
    "\n",
    "print(\"Fighter bout stats\")\n",
    "basic_statistics(data_ufc_fighter_bout_stats_R)\n",
    "\n",
    "print(\"Fighter infight moves stats\")\n",
    "basic_statistics(data_ufc_fighter_infight_moves_stats_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above stats show all numeric attributes from fighter R. We believe that B and R attribute pairs follow the same distribution and that it suffices to describe just one fighter for first insights. At a later steps we will also look at the distribution of both fighters' numeric attributes. From the description we can already see that there are missing values if we look at the count. The count also reveals that there is a bunch of count groups with equal counts hinting that some attributes might be missing together. E.g. we can see that all \"Fighter infight moves stats\" have the same count 4494 which is smaller than the number of rows in this data set. By comparing the mean and the median (labeled as 50%) we can confirm the existence of univariate outliers. We see that e.g. R_avg_REV has a median of 0 while the mean is 0.153263. The 3rd quartile is 0.213346 so the mean is much closer to the 3rd quartile than the median. This is an indication of skewness (left-tailed) and skewed variables are problematic for outlier detection with simple methods such as boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import cm\n",
    "\n",
    "data_corr = data_ufc_fighter_infight_moves_stats_R.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_merged_scaled = pd.DataFrame(scaler.fit_transform(data_corr),\n",
    "                                  columns=data_corr.columns)\n",
    "\n",
    "df = data_corr\n",
    "fig, ax = plt.subplots(figsize=(25,20))\n",
    "plt.tight_layout()\n",
    "corr = data_merged_scaled.corr()\n",
    "im = ax.imshow(corr,cmap='gray')\n",
    "\n",
    "# Decorations\n",
    "ax.set_xticks(np.arange(len(df.columns)))\n",
    "ax.set_yticks(np.arange(len(df.columns)))\n",
    "ax.set_xticklabels(df.columns)\n",
    "ax.set_yticklabels(df.columns)\n",
    "ax.set_ylim(len(df.columns)-0.5, -0.5) # just here due to a bug in matplotlib 3.1.1. fixed in 3.1.2\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    for j in range(len(df.columns)):\n",
    "        text = ax.text(j, i, round(corr.iloc[i, j],2),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "        \n",
    "plt.title('Pearson Correlogram for fighter infight moves stats', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regression problem one would use a correlogram to get an idea how well the attributes are able to predict the outcome based on the correlation with the outcome variable. But here we have no outcome variable(s) included. So why do we plot a correlogram? It can help us to detect multicolinearity which in turn we might want to remove for certain ML algorithms. In the case of \"fighter infight moves\" features we see that every feature pair with suffixes _att and _landed are highly correlated to each other, thus, we could remove features having one of these suffixes to avoid multicolinearity. Another example of Colinearity is the correlation between R_avg_SIG_STR_att and R_avg_DISTANCE_att. This is because most strikes are from the distance and we know already that R_avg_DISTANCE_att is a subset of R_avg_SIG_STR_att. Therefore, we don't need the whole set **and** each subset for explaining the outcome, thus, we can just remove R_avg_SIG_STR_att to explain the outcome. There are some online [references](https://medium.com/@raj5287/effects-of-multi-collinearity-in-logistic-regression-svm-rf-af6766d91f1b) stating that it could be a problem for SVMs while [others](https://towardsdatascience.com/your-beginner-guide-to-basic-classification-models-logistic-regression-and-svm-b7eef864ec9a) state that there is no impact. It seems that we have to find out for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ufc.info()\n",
    "print(\"data_ufc_basic_bout_stats \\n\", data_ufc_basic_bout_stats.isnull().sum(axis=0))\n",
    "print(\"data_ufc_basic_fighter_stats_R\\n\", data_ufc_basic_fighter_stats_R.isnull().sum(axis=0))\n",
    "print(\"data_ufc_basic_fighter_stats_B\\n\", data_ufc_basic_fighter_stats_B.isnull().sum(axis=0))\n",
    "print(\"data_ufc_fighter_bout_stats_R\\n\", data_ufc_fighter_bout_stats_R.isnull().sum(axis=0))\n",
    "print(\"data_ufc_fighter_bout_stats_B\\n\", data_ufc_fighter_bout_stats_B.isnull().sum(axis=0))\n",
    "print(\"data_ufc_fighter_infight_moves_stats_R\\n\", data_ufc_fighter_infight_moves_stats_R.isnull().sum(axis=0))\n",
    "print(\"data_ufc_fighter_infight_moves_stats_B\\n\", data_ufc_fighter_infight_moves_stats_B.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first group of attributes (mainly nominal) has just 23 missing values in the attribute \"Referee\". The missing values for this rather irrelevant attribute will be neglected. The basic fighter stats group reveals already something interesting: There are twice as much missing values for the fighter B than for R. This phenomena can also be observed in the remaining two sets of attributes. Another observation is that attributes from group 3 and 4 (data_ufc_fighter_bout_stats and data_ufc_fighter_infight_moves_stats) are missing together, for R and B respectively. To learn more about the missingness we will plot the attributes with missing values of each fighter now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_B = pd.merge(data_ufc_fighter_infight_moves_stats_B,\n",
    "                          data_ufc_fighter_bout_stats_B['B_total_time_fought(seconds)'], \n",
    "                          left_index=True, \n",
    "                          right_index=True).merge(data_ufc_basic_fighter_stats_B, \n",
    "                                                  left_index=True,\n",
    "                                                  right_index=True)\n",
    "\n",
    "missing_data_R = pd.merge(data_ufc_fighter_infight_moves_stats_R,\n",
    "                          data_ufc_fighter_bout_stats_R['R_total_time_fought(seconds)'], \n",
    "                          left_index=True, \n",
    "                          right_index=True).merge(data_ufc_basic_fighter_stats_R, \n",
    "                                                  left_index=True,\n",
    "                                                  right_index=True)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,10))\n",
    "sns.heatmap(missing_data_B.isnull(),\n",
    "            cbar=False,\n",
    "            #linewidths=.0001\n",
    "            ax=axes[0]\n",
    "            )\n",
    "axes[0].set_title(\"Missing Data B\")\n",
    "\n",
    "sns.heatmap(missing_data_R.isnull(),\n",
    "            cbar=False,\n",
    "            #linewidths=.0001\n",
    "            ax=axes[1]\n",
    "            )\n",
    "axes[1].set_title(\"Missing Data R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution of the missing values (white lines) of the largest visible group of attributes in the plot it seems that the values are missing completely at random. In the earlier years (bigger indexes) the sparsity is greater though. In most recent years the missing values have become less which might be explained by the greater access of digital tools to create the records. It is not clear why B has twice as much missing values than R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will hold a bunch of data sets we will explore more closely. Our biggest interest lies in exploring men and women separately but also different weight classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual exploration\n",
    "# Plot basic statistics\n",
    "# Identify interesting subpopulations\n",
    "## E.g. only male fighters and only 4-5 most popular weight classes\n",
    "# Form hypotheses and identify actions\n",
    "## E.g. which attributes do contribute significantly to the weight class\n",
    "# Transform the hypothesis into a data mining goal, if possible\n",
    "data_ufc_women = data_ufc[data_ufc['weight_class'].isin([\"Women's Flyweight\",\n",
    "                                                         \"Women's Strawweight\",\n",
    "                                                         \"Women's Bantamweight\",\n",
    "                                                         \"Women's Featherweight\"])]\n",
    "data_ufc_men = data_ufc[~data_ufc.isin(data_ufc_women)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ufc_men.hist(figsize=(35,30),\n",
    "                  bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to distinguish between male and female fighters as it is a common separation in sports. Above we plotted the male fighters which are the far bigger subset. We noticed several things:\n",
    "* Countrary to the test statistics we did in the data description section the distribution of R and B attribute pairs look very similar. Therefore, it sufficies to only focus our investigation on one fighter label, e.g. R.\n",
    "* We can see that some attributes have little to no distribution. Those attributes are for instance B_draw, R_draw, R_win_by_TKO_Doctor_Stoppage, B_win_by_TKO_Doctor_Stoppage, R_win_by_Decision_Majority. We will exclude them in the further process as they have little variance and thus will not be important for explaining the outcome of weight classes. \n",
    "* Another interesting thing is that there are much more blue fighters who have not won any fight than red ones (B_wins vs R_wins). \n",
    "* The skewness of wins and losses does also reveal something interesting. As their distribution is the same it means that there are as many fighters who have not won a fight as there are fighters who have not loss any fight. But how does this make sense? It does if there are many fighters with just one record. We will elaborate on this in the next cell.\n",
    "* There is a lot of skewness in general. Using simple boxplots to detect outliers would therefore be a problem as they rely on symetric data. As we are dealing with highly dimensional data we will need multivariate outlier detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fighters = data_ufc_men.groupby('R_fighter').size().sort_values()\n",
    "b_fighters = data_ufc_men.groupby('B_fighter').size().sort_values()\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].hist(x=r_fighters,bins=23)\n",
    "axes[1].hist(x=b_fighters,bins=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show how many entries there are in the data for R and B fighters. We see that there are many \"one-fight-entries\" which supports our finding in the previous step about the similarly skewed wins and losses. This means that a lot of fighters are recorded just once and thus there are many who have not lost or not won a single fight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify special values and catalog their meaning\n",
    "# Verify that the meanings of attributes and contained values fit\n",
    "# Identify missing attributes and blank fields\n",
    "# Establish the meaning of missing data ! Why is it missing?\n",
    "# Check for deviations, decide whether it is “noise” or may indicate an interesting phenomenon\n",
    "# Check for plausability of values\n",
    "# Review any attributes that give answers that conflict with common sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "#### Types of missing data and suitable methods\n",
    "#### MCAR: \n",
    " - means that there is no relationship between the missingness of the data and any of the values.\n",
    " - As in this case the data is missing at completely random spots there is the option to also delete the row where this is the case. This is mainly due to the fact, that removing random rows does not create any bias. This would not be true for the other cases (MAR, MNAR)\n",
    "\n",
    "#### MAR: \n",
    " - means that that there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data.\n",
    " - In this case deletion is no option, as this could create bias in the data. For the records imputation is a better choice.\n",
    "\n",
    "#### MNAR: \n",
    " - means that there is a systematic relationship between the propensity of a value to be missing and its values. \n",
    " - Similarily to MAR here deletion is also no option, as this would create bias. Imputation is the option of coice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(data_ufc.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of attributes with missing values. This seems quite a lot to analyze and identify the pattern. However when taking a closer look it becomes clear that it there is actually a very strong pattern: most of the values are missing exactly the same time (650 and 1265 times). By understanding this pattern we can assume that the values are missing at random, which means we cant simply drop the NA values. To create the least amount of bias we decided to use imputation of the most frequent value for these cases.\n",
    "\n",
    "Other then this there is not a lot of missing values - the ones that are missing are weight, height, stance and the referee. For all of those we dont have any background information. In order to not create any bias we decided to treat them as MNAR and impute also with the most frequent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data_ufc_men.groupby('weight_class')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "#ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group['R_Height_cms'], group['R_Weight_lbs'],\n",
    "            marker='o', linestyle='', ms=8, label=name)\n",
    "ax.set_xlabel('R_Height_cms', fontsize=16)\n",
    "ax.set_ylabel('R_Weight_lbs', fontsize=16)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 2-dimensional plot above shows a few vertical outliers. We first want to detect them using ellipsoides and then use this approach to detect multivariate outliers. We will need to tune the epsilon parameter (contamination) for this purpose until we only detect those outliers that are also visually obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate outlier detection with dbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# preprocessing\n",
    "data_ufc_men_o = data_ufc_men.copy()\n",
    "data_ufc_men_o = data_ufc_men_o.loc[:,['R_Height_cms',\n",
    "                                     'R_Weight_lbs']].dropna()\n",
    "# outlier detection\n",
    "outlier_detection_1 = EllipticEnvelope(contamination=0.1)\n",
    "outlier_detection_1.fit(data_ufc_men_o)\n",
    "prediction_1 = outlier_detection_1.predict(data_ufc_men_o)\n",
    "\n",
    "outlier_detection_2 = EllipticEnvelope(contamination=0.005)\n",
    "outlier_detection_2.fit(data_ufc_men_o)\n",
    "prediction_2 = outlier_detection_2.predict(data_ufc_men_o)\n",
    "\n",
    "data_ufc_men_o['outliers_1'] = prediction_1\n",
    "data_ufc_men_o['outliers_2'] = prediction_2\n",
    "\n",
    "# Plotting outliers\n",
    "groups = data_ufc_men_o.groupby('outliers_1')\n",
    "groups_2 = data_ufc_men_o.groupby('outliers_2')\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "for name, group in groups:\n",
    "    axes[0].plot(group['R_Height_cms'], group['R_Weight_lbs'],\n",
    "            marker='o', linestyle='', ms=8, label=name)\n",
    "    \n",
    "for name, group in groups_2:\n",
    "    axes[1].plot(group['R_Height_cms'], group['R_Weight_lbs'],\n",
    "            marker='o', linestyle='', ms=8, label=name)\n",
    "    \n",
    "axes[0].set_xlabel('R_Height_cms', fontsize=16)\n",
    "axes[0].set_ylabel('R_Weight_lbs', fontsize=16)\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Outlier detection with epsilon=0.1\")\n",
    "\n",
    "axes[1].set_xlabel('R_Height_cms', fontsize=16)\n",
    "axes[1].set_title(\"Outlier detection with epsilon=0.005\")\n",
    "axes[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the choice of epsilon is very important. The outliers shown in the right plot are compliant with our visually detected outliers. We will use this setting to detect multivariate outliers now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate outlier detection with dbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# preprocessing\n",
    "data_ufc_men_om = data_ufc_men.copy()\n",
    "data_ufc_men_om = data_ufc_men_om.loc[:,[\n",
    "                                      'R_Height_cms',\n",
    "                                      'R_Weight_lbs',\n",
    "                                      'R_win_by_Decision_Majority',\n",
    "                                      'R_win_by_Decision_Split',\n",
    "                                      'R_win_by_Decision_Unanimous',\n",
    "                                      'R_win_by_KO/TKO',\n",
    "                                      'R_win_by_Submission',\n",
    "                                      'R_win_by_TKO_Doctor_Stoppage',\n",
    "                                      'R_wins',\n",
    "                                      'R_losses',\n",
    "                                      'R_current_lose_streak',\n",
    "                                      'R_current_win_streak',\n",
    "                                      'R_longest_win_streak',\n",
    "                                      'R_total_rounds_fought',\n",
    "                                      'R_total_time_fought(seconds)',\n",
    "                                      'R_total_title_bouts']].dropna()\n",
    "\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "data_ufc_men_om_scaled = pd.DataFrame(scaler.fit_transform(data_ufc_men_om),\n",
    "                                      columns=data_ufc_men_om.columns)\n",
    "\n",
    "# outlier detection\n",
    "outlier_detection = EllipticEnvelope(contamination=0.005)\n",
    "outlier_detection.fit(data_ufc_men_om_scaled)\n",
    "prediction = outlier_detection.predict(data_ufc_men_om_scaled)\n",
    "\n",
    "# Assigning outlier flag to scaled data set\n",
    "data_ufc_men_om_scaled['outliers'] = prediction\n",
    "groups = data_ufc_men_om_scaled.groupby('outliers')\n",
    "\n",
    "o1 = data_ufc_men_om_scaled.query('outliers == -1').iloc[0]\n",
    "o1 = o1.drop(labels='outliers')\n",
    "\n",
    "mean = pd.Series(outlier_detection.location_, index=data_ufc_men_om.columns)\n",
    "\n",
    "# Plotting outlier vs non-outlier\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "bar1_pos = np.arange(len(data_ufc_men_om.columns))\n",
    "bar2_pos = [x + 0.30 for x in bar1_pos]\n",
    "xticks = [r + 0.15 for r in range(len(data_ufc_men_om.columns))]\n",
    "\n",
    "plt.bar(x=bar1_pos,height=o1, width=0.30, label='outlier')\n",
    "plt.bar(x=bar2_pos,height=mean, width=0.30, label='ellipsoid mean')\n",
    "plt.xticks(xticks, data_ufc_men_om.columns, rotation=90)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot above opposes one outlier to the subset mean scaled with the MinMaxScaler. The subset we were investigating comprises only male fighters and the attributes we chose are from the \"fighter bout stats\" attribute set. The method we used to find multivarite outliers uses ellipsoids for outlier detection and a level of contamination, i.e. the proporation of outliers in the data set. The condition n_samples > n_features ** 2 needs to be fullfilled in order to work properly which holds true in our case. The outlier shown above has some interesting settings. While the fighter's height and weight are close to the mean his number of total title bouts, wins and losses are far away which is truly unusal for this data set. Also his current loss streak is something which stands out. Eventhough outliers will not be problematic in our chosen machine learning algorithms our approach demonstrates how multivariate outliers can be detected in a highly dimensional data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling: If the entire dataset is too large to be processed in its entirety, choose a subsampling strategy to get the dataset to a manageable size. Describe in your report why and how you did it. Make sure your experiment is repeatable. (No manual selection of instances, everything must be in code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "Missing values are imputed with the strategy described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_num.fit(data_ufc)\n",
    "\n",
    "data_ufc_clean =  pd.DataFrame(imp_num.transform(data_ufc), columns=data_ufc.columns)\n",
    "print(data_ufc_clean.isna().sum().sum())\n",
    "\n",
    "## Drop non-predictive nominal attributes and Date (Blue Figher Name, Red Fighter Name, Referee, Date, Location)\n",
    "#rint(data_ufc_clean.iloc[[0,1,2,3,4]].head())\n",
    "data_ufc_clean.drop(['Referee','location','date','B_fighter','R_fighter'], axis=1, inplace=True)\n",
    "data_ufc_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Get the data into the form needed for training your two algorithms. Describe your preprocessing steps (e.g. transcoding, scaling), why you did it and how you did it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "data_ufc_clean['Winner'] = lb.fit_transform(data_ufc_clean['Winner']) # Winner\n",
    "#data_ufc_clean[6] = lb.fit_transform(data_ufc_clean[6])\n",
    "data_ufc_clean['B_Stance'] = lb.fit_transform(data_ufc_clean['B_Stance']) # Stance of Blue fighter\n",
    "data_ufc_clean['R_Stance'] = lb.fit_transform(data_ufc_clean['R_Stance']) # Stance of Red fighter\n",
    "data_ufc_clean.head() \n",
    "data_ufc_clean.to_csv(\"data_ufc_clean\", index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick two significantly different classification algorithms, i.e. NO two variations of the same algorithm.\n",
    "* SVM and Random Forest\n",
    "* Class attribute: weight_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe why you chose the respective algorithms and briefly summarize their characteristics and the semantics underlying its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test desgin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be tested using an incrementally varying train/test split approach. We will start with a split of 5%/95% (train/test) and increment the split ratio by 10% until 95%/5% is reached.\n",
    "For each training set size we will perform multiple runs to observe the sensitivity to the actual subset used for training a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "# Paramters\n",
    "## Explore paramters with Grid Search and cross validation\n",
    "# Training and test\n",
    "print(data_ufc_clean[[5,6,7]])\n",
    "#X_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your two algorithms in 3 separate experiment tracks as detailed below and evaluate your results with a reasonable quality measure for your algorithms (e.g.: (micro/macro) Precision/Recall, Mean Absolute Error,…). Interpret your results using both graphs and summaries (e.g. confusion matrices). For each of the 3 experiment tracks you should separately vary and document:\n",
    "* Parameters: If the classifier has specific parameters, explore their effect with different settings using 10-fold cross-validation and document the parameters and the results and analyze the sensitivity of classification outcomes against these parameters. Specifically, test extreme/obviously wrong settings and analyze the results\n",
    "* Scaling: where possible, try different scaling approaches (min/max, zero mean/unit variance, length) using the best parameters identified above and observe the difference in classification performance using 10-fold cross-validation. Analyze the reasons for the effects observed, test useful and also non-useful (!) scalings and summarize your findings as well as analyze reasons why specific scalings make sense in a given setting.\n",
    "* Training / test set splits: Use the best parameter setting and scaling identified above and evaluate the effect of different training and test set splits. Start with a small training set and increase it in small increments (e.g. 10 sets from 5% / 95% (train/test) in 10%-increments to 95%/5% (train/test)) and observe performance changes. Perform multiple runs with each training set size to observe the sensitivity to the actual subset used for training a specific run. Analyze the variance in performance obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier_svm = svm.SVC()  \n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', classifier_svm)\n",
    "    ])\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [0.1,1,10,50,100,200,500], \n",
    "   'classifier__kernel': ['linear'],\n",
    "   'pca__n_components': [2, 5, 10, 15]\n",
    "  },\n",
    "  {'classifier__C': [0.1,1,10,50,100,200,500], \n",
    "   'classifier__gamma': [0.1, 0.01, 0.001, 0.0001], \n",
    "   'classifier__kernel': ['rbf'],\n",
    "   'pca__n_components': [2, 5, 10, 15]\n",
    "  } \n",
    " ]\n",
    "\n",
    "cv_classifier_svm = GridSearchCV(pipe, \n",
    "                                 param_grid=param_grid, \n",
    "                                 cv = 10, \n",
    "                                 iid=False, \n",
    "                                 scoring = scores,\n",
    "                                 refit = 'f1',\n",
    "                                 return_train_score = True)\n",
    "                                \n",
    "cv_classifier_svm.fit(X_train, Y_train)\n",
    "prediction_svm = cv_classifier_svm.predict(X_test) # predict on the test set\n",
    "\n",
    "#print(label.inverse_transform(prediction_svm)) # Output the prediction results\n",
    "print(cv_classifier_svm.cv_results, cv_classifier_svm.best_params) # print the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asses Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What trends do you observe in each set of experiments?\n",
    "* How easy was it to interpret the algorithm and its performance?\n",
    "* Which classes are most frequently mixed-up? (and why?)\n",
    "* What parameter settings cause performance changes?\n",
    "* Do both algorithms show the same behavior in performance, performance degradation / robustness against\n",
    "  * smaller and larger training set sizes?\n",
    "  * variations in parameter settings?\n",
    "* Did you observe or can you force and document characteristics such as over-learning?\n",
    "* How does the performance change with different amounts of training data being available? What are the best scalings (per attribute / per vector) and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
